{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simclr_pytorch.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaw043AQguBh"
      },
      "source": [
        "# Bharath Gunasekarn\n",
        "# SimCLR pytorch\n",
        "\n",
        "# Code was written in reference to  https://medium.com/analytics-vidhya/understanding-simclr-a-simple-framework-for-contrastive-learning-of-visual-representations-d544a9003f3c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dc2VTrbefOe"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "tsne = TSNE()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkktXyGxIZtm"
      },
      "source": [
        "# Get Data\n",
        "Using a subset of cifar10 dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXPbaDKX-nQ1"
      },
      "source": [
        "# Download Data\n",
        "%%capture\n",
        "!rm -rf ./data\n",
        "!mkdir -p data\n",
        "!cd data\n",
        "!wget https://raw.githubusercontent.com/bharathGuna/CMPE-297-Special-Topics/main/assignment1/data/cifar.zip -P ./data/\n",
        "!unzip data/cifar.zip -d data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPZXktsPITT9"
      },
      "source": [
        "train_files = sorted(os.listdir('data/train'))\n",
        "test_files = sorted(os.listdir('data/test'))\n",
        "\n",
        "random.seed(1)\n",
        "\n",
        "train = random.sample(train_files, len(train_files))\n",
        "eval = random.sample(train, len(train_files) // 10)\n",
        "test = random.sample(test_files, len(test_files))\n",
        "\n",
        "label_set = set()\n",
        "train_labels = []\n",
        "test_labels = []\n",
        "eval_labels = [] \n",
        "for name in train:\n",
        "  label = name.split('_')[0]\n",
        "  label_set.add(label)\n",
        "  train_labels.append(label)\n",
        "\n",
        "for name in eval:\n",
        "  label = name.split('_')[0]\n",
        "  eval_labels.append(label)\n",
        "\n",
        "for name in test:\n",
        "  label = name.split('_')[0]\n",
        "  test_labels.append(label)\n",
        "\n",
        "label_map = {}\n",
        "\n",
        "for label,value in zip(label_set,[0,1,2,3,4]):\n",
        "  label_map[label] = value\n",
        "\n",
        "label_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX9gYSrLOQwp"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CZRgKjHOTCf"
      },
      "source": [
        "# Modifys the color of the images\n",
        "def get_color_distortion(s=1.0):\n",
        "    color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "    rnd_color_jitter =  transforms.RandomApply([color_jitter], p=0.8)\n",
        "    rnd_gray =  transforms.RandomGrayscale(p=0.2)\n",
        "    color_distort =  transforms.Compose([rnd_color_jitter, rnd_gray])\n",
        "    return color_distort\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ejEdZjDRM9L"
      },
      "source": [
        "# Image DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fRGk15eRMSO"
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, datapath, filenames, labels, mutation):\n",
        "        self.datapath = datapath\n",
        "        self.filenames = filenames\n",
        "        self.labels = labels\n",
        "        self.mutation = mutation\n",
        "\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def tensorify(self, img):\n",
        "        return transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(\n",
        "            transforms.ToTensor()(img)\n",
        "            )\n",
        "\n",
        "    def augmented_image(self, img):\n",
        "        return get_color_distortion(1)(\n",
        "            transforms.RandomResizedCrop(224)(img)\n",
        "            )    \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        img = transforms.Resize((224, 224))(\n",
        "                                Image.open(os.path.join(self.datapath, self.filenames[idx])).convert('RGB')\n",
        "                            )\n",
        "        if self.mutation:\n",
        "          return {\n",
        "          'image1':self.tensorify(\n",
        "              self.augmented_image(img)\n",
        "              ), \n",
        "          'image2': self.tensorify(\n",
        "              self.augmented_image(img)\n",
        "              ),\n",
        "          'label': self.labels[idx]\n",
        "          }\n",
        "        else:\n",
        "          return {\n",
        "          'image':self.tensorify(\n",
        "              transforms.RandomResizedCrop(244)(img)\n",
        "              ),\n",
        "          'label': self.labels[idx]\n",
        "          }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0DtmgdkZPj_"
      },
      "source": [
        "training_dataset_mutated = ImageDataset('data/train', train, train_labels, mutation=True)\n",
        "training_dataset = ImageDataset('data/train', eval, eval_labels, mutation=False)\n",
        "testing_dataset = ImageDataset('data/test', test, test_labels, mutation=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vDX1MPkZrDF"
      },
      "source": [
        "dataloader_training_dataset_mutated = DataLoader(training_dataset_mutated, batch_size=64, shuffle=True, num_workers=2)\n",
        "dataloader_training_dataset = DataLoader(training_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "dataloader_testing_dataset = DataLoader(testing_dataset, batch_size=64, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhfK1uM0Z0_U"
      },
      "source": [
        "# defining our deep learning architecture\n",
        "resnet = resnet18(pretrained=False)\n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    ('fc1', nn.Linear(resnet.fc.in_features, 100)),\n",
        "    ('added_relu1', nn.ReLU(inplace=True)),\n",
        "    ('fc2', nn.Linear(100, 50)),\n",
        "    ('added_relu2', nn.ReLU(inplace=True)),\n",
        "    ('fc3', nn.Linear(50, 25))\n",
        "]))\n",
        "\n",
        "resnet.fc = classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7YQnid9Z8c8"
      },
      "source": [
        "device = torch.device('cuda')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjg5aP5tZ9fJ"
      },
      "source": [
        "resnet.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6D5DtK5aIDX"
      },
      "source": [
        "tau = 0.05\n",
        "\n",
        "def loss_function(a, b):\n",
        "    a_norm = torch.norm(a, dim=1).reshape(-1, 1)\n",
        "    a_cap = torch.div(a, a_norm)\n",
        "    b_norm = torch.norm(b, dim=1).reshape(-1, 1)\n",
        "    b_cap = torch.div(b, b_norm)\n",
        "    a_cap_b_cap = torch.cat([a_cap, b_cap], dim=0)\n",
        "    a_cap_b_cap_transpose = torch.t(a_cap_b_cap)\n",
        "    b_cap_a_cap = torch.cat([b_cap, a_cap], dim=0)\n",
        "    sim = torch.mm(a_cap_b_cap, a_cap_b_cap_transpose)\n",
        "    sim_by_tau = torch.div(sim, tau)\n",
        "    exp_sim_by_tau = torch.exp(sim_by_tau)\n",
        "    sum_of_rows = torch.sum(exp_sim_by_tau, dim=1)\n",
        "    exp_sim_by_tau_diag = torch.diag(exp_sim_by_tau)\n",
        "    numerators = torch.exp(torch.div(torch.nn.CosineSimilarity()(a_cap_b_cap, b_cap_a_cap), tau))\n",
        "    denominators = sum_of_rows - exp_sim_by_tau_diag\n",
        "    num_by_den = torch.div(numerators, denominators)\n",
        "    neglog_num_by_den = -torch.log(num_by_den)\n",
        "    return torch.mean(neglog_num_by_den)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iErgdyQCanT6"
      },
      "source": [
        "\n",
        "# Defining data structures for storing training info\n",
        "\n",
        "losses_train = []\n",
        "num_epochs = 20\n",
        "\n",
        "# using SGD optimizer\n",
        "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "if not os.path.exists('results'):\n",
        "    os.makedirs('results')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVDAiXCbav0v"
      },
      "source": [
        "# Boolean variable on whether to perform training or not \n",
        "# Note that this training is unsupervised, it uses the NT-Xent Loss function\n",
        "\n",
        "TRAINING = True\n",
        "\n",
        "def get_mean_of_list(L):\n",
        "    return sum(L) / len(L)\n",
        "\n",
        "if TRAINING:\n",
        "    # get resnet in train mode\n",
        "    resnet.train()\n",
        "\n",
        "    # run a for loop for num_epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # a list to store losses for each epoch\n",
        "        epoch_losses_train = []\n",
        "\n",
        "        # run a for loop for each batch\n",
        "        for (_, sample_batched) in enumerate(dataloader_training_dataset_mutated):\n",
        "            \n",
        "            # zero out grads\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # retrieve x1 and x2 the two image batches\n",
        "            x1 = sample_batched['image1']\n",
        "            x2 = sample_batched['image2']\n",
        "\n",
        "            # move them to the device\n",
        "            x1 = x1.to(device)\n",
        "            x2 = x2.to(device)\n",
        "\n",
        "            # get their outputs\n",
        "            y1 = resnet(x1)\n",
        "            y2 = resnet(x2)\n",
        "\n",
        "            # get loss value\n",
        "            loss = loss_function(y1, y2)\n",
        "            \n",
        "            # put that loss value in the epoch losses list\n",
        "            epoch_losses_train.append(loss.cpu().data.item())\n",
        "\n",
        "            # perform backprop on loss value to get gradient values\n",
        "            loss.backward()\n",
        "\n",
        "            # run the optimizer\n",
        "            optimizer.step()\n",
        "\n",
        "        # append mean of epoch losses to losses_train, essentially this will reflect mean batch loss\n",
        "        \n",
        "        loss = get_mean_of_list(epoch_losses_train) \n",
        "        losses_train.append(loss)\n",
        "        print(\"Epoch: {} Loss: {}\".format(epoch,loss))\n",
        "\n",
        "        # Plot the training losses Graph and save it\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        sns.set_style('darkgrid')\n",
        "        plt.plot(losses_train)\n",
        "        plt.legend(['Training Losses'])\n",
        "        plt.savefig('losses.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Store model and optimizer files\n",
        "        torch.save(resnet.state_dict(), 'results/model.pth')\n",
        "        torch.save(optimizer.state_dict(), 'results/optimizer.pth')\n",
        "        np.savez(\"results/lossesfile\", np.array(losses_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PX9xyLbohj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "tsne = TSNE()\n",
        "\n",
        "def plot_vecs_n_labels(df,fname):\n",
        "    fig = plt.figure(figsize = (10, 10))\n",
        "    plt.axis('off')\n",
        "    sns.set_style(\"darkgrid\")\n",
        "    sns.scatterplot(data=df,x='x', y='y',  hue=\"label\", legend='full')\n",
        "    plt.legend(['car', 'dog', 'cat', 'elephant','airplane'])\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "for (_, sample_batched) in enumerate(dataloader_training_dataset):\n",
        "    x = sample_batched['image']\n",
        "    x = x.to(device)\n",
        "    y = resnet(x)\n",
        "    y_tsne = tsne.fit_transform(y.cpu().data)\n",
        "    labels = sample_batched['label']\n",
        "    df = pd.DataFrame(y_tsne, columns=['x','y'])\n",
        "    df['label'] = np.array(labels)\n",
        "    plot_vecs_n_labels(df,'tsne_train_last_layer.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}