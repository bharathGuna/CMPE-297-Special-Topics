{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceiver Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFD-7ydwN3fQ"
      },
      "source": [
        "Bharath Gunasekaran \n",
        "\n",
        "This colab implements Perceiver ml model in Keras and applies Image Classification on a subset of cipher100 dataset. \n",
        "\n",
        "References:\n",
        "\n",
        "https://keras.io/examples/vision/perceiver_image_classification/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7eO1shKOF2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e8d06d-cd40-47f1-af5b-6ac75bd7fff1"
      },
      "source": [
        "pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 317 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 409 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 440 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 471 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 491 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 501 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 512 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 532 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 542 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 563 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 573 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 583 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 593 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 604 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 614 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 634 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 645 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 665 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 675 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 686 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 696 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 706 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 716 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 727 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 737 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 747 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 768 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 778 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 788 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 808 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 819 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 829 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 839 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 849 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 860 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 870 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 880 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 890 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 901 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 911 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 921 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 942 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 952 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 962 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 983 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 993 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSSrQxKCN3fY"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mML9PZ3LN3fZ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "from imutils import paths\n",
        "import random\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XPdz9XkN3fb"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YbyuakZr568"
      },
      "source": [
        "\n",
        "# Download Data\n",
        "%%capture\n",
        "!rm -rf ./data\n",
        "!mkdir -p data\n",
        "!cd data\n",
        "!wget https://raw.githubusercontent.com/bharathGuna/CMPE-297-Special-Topics/main/assignment2/data/cifar.zip -P ./data/\n",
        "!unzip data/cifar.zip -d data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Srv8o21N3fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dbb2351-b15d-49f3-e42e-59abda81ed9a"
      },
      "source": [
        "num_classes = 5\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "train = keras.preprocessing.image_dataset_from_directory(\n",
        "    'data/train',\n",
        "    labels=\"inferred\",\n",
        "    class_names=[\"cat\",\"car\",\"dog\",\"elephant\",\"airplane\"],\n",
        "    batch_size=32,\n",
        "    image_size=(32,32)\n",
        ")\n",
        "\n",
        "test = keras.preprocessing.image_dataset_from_directory(\n",
        "    'data/test',\n",
        "    labels=\"inferred\",\n",
        "    class_names=[\"cat\",\"car\",\"dog\",\"elephant\",\"airplane\"],\n",
        "    batch_size=32,\n",
        "    image_size=(32,32)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1250 files belonging to 5 classes.\n",
            "Found 250 files belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lln7FCcJN3fc"
      },
      "source": [
        "## Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3plceFcN3fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19851b2b-7d05-4b54-d4d8-8187b15044ea"
      },
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "dropout_rate = 0.2\n",
        "image_size = 64  # We'll resize input images to this size.\n",
        "patch_size = 2  # Size of the patches to be extract from the input images.\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n",
        "latent_dim = 256  # Size of the latent array.\n",
        "projection_dim = 256  # Embedding size of each element in the data and latent arrays.\n",
        "num_heads = 8  # Number of Transformer heads.\n",
        "ffn_units = [\n",
        "    projection_dim,\n",
        "    projection_dim,\n",
        "]  # Size of the Transformer Feedforward network.\n",
        "num_transformer_blocks = 4\n",
        "num_iterations = 2  # Repetitions of the cross-attention and Transformer modules.\n",
        "classifier_units = [\n",
        "    projection_dim,\n",
        "    num_classes,\n",
        "]  # Size of the Feedforward network of the final classifier.\n",
        "\n",
        "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
        "print(f\"Patches per image: {num_patches}\")\n",
        "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")\n",
        "print(f\"Latent array shape: {latent_dim} X {projection_dim}\")\n",
        "print(f\"Data array shape: {num_patches} X {projection_dim}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 64 X 64 = 4096\n",
            "Patch size: 2 X 2 = 4 \n",
            "Patches per image: 1024\n",
            "Elements per patch (3 channels): 12\n",
            "Latent array shape: 256 X 256\n",
            "Data array shape: 1024 X 256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U26AdpS9N3fg"
      },
      "source": [
        "## Use data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC6eepbPN3fh"
      },
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOb2DFXLN3fi"
      },
      "source": [
        "## Implement Feedforward network (FFN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTxkXhwxN3fj"
      },
      "source": [
        "\n",
        "def create_ffn(hidden_units, dropout_rate):\n",
        "    ffn_layers = []\n",
        "    for units in hidden_units[:-1]:\n",
        "        ffn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n",
        "\n",
        "    ffn_layers.append(layers.Dense(units=hidden_units[-1]))\n",
        "    ffn_layers.append(layers.Dropout(dropout_rate))\n",
        "\n",
        "    ffn = keras.Sequential(ffn_layers)\n",
        "    return ffn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70lOHGYcN3fj"
      },
      "source": [
        "Creating Patch Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1pxmJNsN3fk"
      },
      "source": [
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRbiHtMrN3fl"
      },
      "source": [
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patches):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
        "        return encoded\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InqP2YI7NWGi"
      },
      "source": [
        "# Perceiver Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK4t8HhON3fm"
      },
      "source": [
        "\n",
        "def create_cross_attention_module(\n",
        "    latent_dim, data_dim, projection_dim, ffn_units, dropout_rate\n",
        "):\n",
        "\n",
        "    inputs = {\n",
        "        # Recieve the latent array as an input of shape [1, latent_dim, projection_dim].\n",
        "        \"latent_array\": layers.Input(shape=(latent_dim, projection_dim)),\n",
        "        # Recieve the data_array (encoded image) as an input of shape [batch_size, data_dim, projection_dim].\n",
        "        \"data_array\": layers.Input(shape=(data_dim, projection_dim)),\n",
        "    }\n",
        "\n",
        "    # Apply layer norm to the inputs\n",
        "    latent_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"latent_array\"])\n",
        "    data_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"data_array\"])\n",
        "\n",
        "    # Create query tensor: [1, latent_dim, projection_dim].\n",
        "    query = layers.Dense(units=projection_dim)(latent_array)\n",
        "    # Create key tensor: [batch_size, data_dim, projection_dim].\n",
        "    key = layers.Dense(units=projection_dim)(data_array)\n",
        "    # Create value tensor: [batch_size, data_dim, projection_dim].\n",
        "    value = layers.Dense(units=projection_dim)(data_array)\n",
        "\n",
        "    # Generate cross-attention outputs: [batch_size, latent_dim, projection_dim].\n",
        "    attention_output = layers.Attention(use_scale=True, dropout=0.1)(\n",
        "        [query, key, value], return_attention_scores=False\n",
        "    )\n",
        "    # Skip connection 1.\n",
        "    attention_output = layers.Add()([attention_output, latent_array])\n",
        "\n",
        "    # Apply layer norm.\n",
        "    attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output)\n",
        "    # Apply Feedforward network.\n",
        "    ffn = create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n",
        "    outputs = ffn(attention_output)\n",
        "    # Skip connection 2.\n",
        "    outputs = layers.Add()([outputs, attention_output])\n",
        "\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRUTv7OhN3fn"
      },
      "source": [
        "\n",
        "def create_transformer_module(\n",
        "    latent_dim,\n",
        "    projection_dim,\n",
        "    num_heads,\n",
        "    num_transformer_blocks,\n",
        "    ffn_units,\n",
        "    dropout_rate,\n",
        "):\n",
        "\n",
        "    # input_shape: [1, latent_dim, projection_dim]\n",
        "    inputs = layers.Input(shape=(latent_dim, projection_dim))\n",
        "\n",
        "    x0 = inputs\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        # Apply layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(x0)\n",
        "        # Create a multi-head self-attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, x0])\n",
        "        # Apply layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # Apply Feedforward network.\n",
        "        ffn = create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n",
        "        x3 = ffn(x3)\n",
        "        # Skip connection 2.\n",
        "        x0 = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=x0)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_mi2ZktN3fn"
      },
      "source": [
        "### Perceiver model\n",
        "\n",
        "The Perceiver model repeats the cross-attention and Transformer modules\n",
        "`num_iterations` times—with shared weights and skip connections—to allow\n",
        "the latent array to iteratively extract information from the input image as it is needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agVOOpp-N3fo"
      },
      "source": [
        "\n",
        "class Perceiver(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        patch_size,\n",
        "        data_dim,\n",
        "        latent_dim,\n",
        "        projection_dim,\n",
        "        num_heads,\n",
        "        num_transformer_blocks,\n",
        "        ffn_units,\n",
        "        dropout_rate,\n",
        "        num_iterations,\n",
        "        classifier_units,\n",
        "    ):\n",
        "        super(Perceiver, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.data_dim = data_dim\n",
        "        self.patch_size = patch_size\n",
        "        self.projection_dim = projection_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.num_transformer_blocks = num_transformer_blocks\n",
        "        self.ffn_units = ffn_units\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.classifier_units = classifier_units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create latent array.\n",
        "        self.latent_array = self.add_weight(\n",
        "            shape=(self.latent_dim, self.projection_dim),\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "        # Create patching module.\n",
        "        self.patcher = Patches(self.patch_size)\n",
        "\n",
        "        # Create patch encoder.\n",
        "        self.patch_encoder = PatchEncoder(self.data_dim, self.projection_dim)\n",
        "\n",
        "        # Create cross-attenion module.\n",
        "        self.cross_attention = create_cross_attention_module(\n",
        "            self.latent_dim,\n",
        "            self.data_dim,\n",
        "            self.projection_dim,\n",
        "            self.ffn_units,\n",
        "            self.dropout_rate,\n",
        "        )\n",
        "\n",
        "        # Create Transformer module.\n",
        "        self.transformer = create_transformer_module(\n",
        "            self.latent_dim,\n",
        "            self.projection_dim,\n",
        "            self.num_heads,\n",
        "            self.num_transformer_blocks,\n",
        "            self.ffn_units,\n",
        "            self.dropout_rate,\n",
        "        )\n",
        "\n",
        "        # Create global average pooling layer.\n",
        "        self.global_average_pooling = layers.GlobalAveragePooling1D()\n",
        "\n",
        "        # Create a classification head.\n",
        "        self.classification_head = create_ffn(\n",
        "            hidden_units=self.classifier_units, dropout_rate=self.dropout_rate\n",
        "        )\n",
        "\n",
        "        super(Perceiver, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Augment data.\n",
        "        augmented = data_augmentation(inputs)\n",
        "        # Create patches.\n",
        "        patches = self.patcher(augmented)\n",
        "        # Encode patches.\n",
        "        encoded_patches = self.patch_encoder(patches)\n",
        "        # Prepare cross-attention inputs.\n",
        "        cross_attention_inputs = {\n",
        "            \"latent_array\": tf.expand_dims(self.latent_array, 0),\n",
        "            \"data_array\": encoded_patches,\n",
        "        }\n",
        "        # Apply the cross-attention and the Transformer modules iteratively.\n",
        "        for _ in range(self.num_iterations):\n",
        "            # Apply cross-attention from the latent array to the data array.\n",
        "            latent_array = self.cross_attention(cross_attention_inputs)\n",
        "            # Apply self-attention Transformer to the latent array.\n",
        "            latent_array = self.transformer(latent_array)\n",
        "            # Set the latent array of the next iteration.\n",
        "            cross_attention_inputs[\"latent_array\"] = latent_array\n",
        "\n",
        "        # Apply global average pooling to generate a [batch_size, projection_dim] repesentation tensor.\n",
        "        representation = self.global_average_pooling(latent_array)\n",
        "        # Generate logits.\n",
        "        logits = self.classification_head(representation)\n",
        "        return logits\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDLys56LN3fq"
      },
      "source": [
        "## Compile, train, and evaluate the mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gja_T_T8N3fr"
      },
      "source": [
        "\n",
        "def run_experiment(model):\n",
        "\n",
        "    # Create LAMB optimizer with weight decay.\n",
        "    optimizer = tfa.optimizers.LAMB(\n",
        "        learning_rate=learning_rate, weight_decay_rate=weight_decay,\n",
        "    )\n",
        "\n",
        "    # Compile the model.\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Create a learning rate scheduler callback.\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.2, patience=3\n",
        "    )\n",
        "\n",
        "    # Create an early stopping callback.\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=15, restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Fit the model.\n",
        "    history = model.fit(train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "    )\n",
        "\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    # Return history to plot learning curves.\n",
        "    return history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnR7N8mdN3fr"
      },
      "source": [
        "Note that training the perceiver model with the current settings on a V100 GPUs takes\n",
        "around 200 seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvrvZgs1N3fr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553cab42-2d73-4a81-a55d-d9b5e019fcdf"
      },
      "source": [
        "perceiver_classifier = Perceiver(\n",
        "    patch_size,\n",
        "    num_patches,\n",
        "    latent_dim,\n",
        "    projection_dim,\n",
        "    num_heads,\n",
        "    num_transformer_blocks,\n",
        "    ffn_units,\n",
        "    dropout_rate,\n",
        "    num_iterations,\n",
        "    classifier_units,\n",
        ")\n",
        "\n",
        "\n",
        "history = run_experiment(perceiver_classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 33s 384ms/step - loss: 1.5926 - acc: 0.3176 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 16s 385ms/step - loss: 1.4989 - acc: 0.3592 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.4869 - acc: 0.3464 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.4388 - acc: 0.3720 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 16s 385ms/step - loss: 1.3823 - acc: 0.3968 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.3206 - acc: 0.4496 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 16s 383ms/step - loss: 1.3371 - acc: 0.4296 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.2990 - acc: 0.4568 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.3075 - acc: 0.4520 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.2805 - acc: 0.4416 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.2516 - acc: 0.4664 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.2269 - acc: 0.4976 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.2434 - acc: 0.4744 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.2310 - acc: 0.4776 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.2025 - acc: 0.4904 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.1784 - acc: 0.5216 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.1649 - acc: 0.5048 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 16s 385ms/step - loss: 1.1553 - acc: 0.5136 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.1334 - acc: 0.5336 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.0795 - acc: 0.5504 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 16s 385ms/step - loss: 1.1330 - acc: 0.5208 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.1074 - acc: 0.5280 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.0756 - acc: 0.5552 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.0750 - acc: 0.5464 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.0684 - acc: 0.5464 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.0452 - acc: 0.5680 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.0322 - acc: 0.5568 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.0170 - acc: 0.5784 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.0145 - acc: 0.5720 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 1.0014 - acc: 0.5672 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.9954 - acc: 0.5824 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.9674 - acc: 0.5968 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.9682 - acc: 0.5944 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.9642 - acc: 0.6072 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.9299 - acc: 0.6072 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 16s 385ms/step - loss: 0.9711 - acc: 0.6088 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.9483 - acc: 0.6168 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.9485 - acc: 0.6016 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.9020 - acc: 0.6160 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.8903 - acc: 0.6392 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 16s 385ms/step - loss: 0.8984 - acc: 0.6288 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.8813 - acc: 0.6264 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.8772 - acc: 0.6328 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 16s 385ms/step - loss: 0.8550 - acc: 0.6376 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.8234 - acc: 0.6680 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.8258 - acc: 0.6608 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.8049 - acc: 0.6616 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 16s 384ms/step - loss: 0.8269 - acc: 0.6592 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 16s 385ms/step - loss: 0.7978 - acc: 0.6568 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 16s 385ms/step - loss: 0.7940 - acc: 0.6728 - top5-acc: 1.0000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,top5-acc,lr\n",
            "313/313 [==============================] - 43s 133ms/step - loss: nan - acc: 0.0118 - top5-acc: 0.0500\n",
            "Test accuracy: 1.18%\n",
            "Test top 5 accuracy: 5.0%\n"
          ]
        }
      ]
    }
  ]
}
