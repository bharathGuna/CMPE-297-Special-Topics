{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PerceiverIO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNNXeFiUJwPA"
      },
      "source": [
        "Bharath Gunasekaran\n",
        "\n",
        "This colab is to user Perciever IO model by Deep Minds to perform an interesting ML task. Implemented Perciever IO to predict a masked word in a sentence is. \n",
        "\n",
        "References:\n",
        "\n",
        "https://colab.research.google.com/github/2796gaurav/code_examples/blob/main/Perceiver/Perceiver_masked_language_modelling.ipynb#scrollTo=ipZs6p0Xk3lb\n",
        "\n",
        "https://medium.com/analytics-vidhya/perceiver-io-a-general-architecture-for-structured-inputs-outputs-4ad669315e7f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECDNYL7cSGj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa82b7d4-fab3-4c6e-e532-4824cfd906e3"
      },
      "source": [
        "# Install dependencies for Google Colab.\n",
        "# If you want to run this notebook on your own machine, you can skip this cell\n",
        "!pip install dm-haiku\n",
        "!pip install einops\n",
        "\n",
        "!mkdir /content/perceiver\n",
        "!touch /content/perceiver/__init__.py\n",
        "!wget -O /content/perceiver/bytes_tokenizer.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/bytes_tokenizer.py\n",
        "!wget -O /content/perceiver/io_processors.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/io_processors.py\n",
        "!wget -O /content/perceiver/perceiver.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/perceiver.py\n",
        "!wget -O /content/perceiver/position_encoding.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/position_encoding.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.4-py3-none-any.whl (284 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 174 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 184 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 194 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 215 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 225 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 235 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 245 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 256 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 284 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.9)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku) (1.15.0)\n",
            "Installing collected packages: dm-haiku\n",
            "Successfully installed dm-haiku-0.0.4\n",
            "Collecting einops\n",
            "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.2\n",
            "--2021-10-09 19:37:23--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/bytes_tokenizer.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1850 (1.8K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/bytes_tokenizer.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]   1.81K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-09 19:37:23 (36.1 MB/s) - ‘/content/perceiver/bytes_tokenizer.py’ saved [1850/1850]\n",
            "\n",
            "--2021-10-09 19:37:23--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/io_processors.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29359 (29K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/io_processors.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]  28.67K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-09 19:37:23 (102 MB/s) - ‘/content/perceiver/io_processors.py’ saved [29359/29359]\n",
            "\n",
            "--2021-10-09 19:37:23--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/perceiver.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30179 (29K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/perceiver.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]  29.47K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-09 19:37:23 (101 MB/s) - ‘/content/perceiver/perceiver.py’ saved [30179/30179]\n",
            "\n",
            "--2021-10-09 19:37:23--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/position_encoding.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8107 (7.9K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/position_encoding.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]   7.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-09 19:37:24 (81.9 MB/s) - ‘/content/perceiver/position_encoding.py’ saved [8107/8107]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgDgS1ZgjY_B"
      },
      "source": [
        "#@title Import\n",
        "from typing import Union\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from perceiver import perceiver, position_encoding, io_processors, bytes_tokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKfqjrHxja8e",
        "outputId": "dc0a910a-8fda-43b7-e367-e174b6d7fce1"
      },
      "source": [
        "\n",
        "#@title Load parameters from checkpoint\n",
        "!wget -O language_perceiver_io_bytes.pickle https://storage.googleapis.com/perceiver_io/language_perceiver_io_bytes.pickle\n",
        "\n",
        "with open(\"language_perceiver_io_bytes.pickle\", \"rb\") as f:\n",
        "  params = pickle.loads(f.read())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-09 19:37:25--  https://storage.googleapis.com/perceiver_io/language_perceiver_io_bytes.pickle\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 804479532 (767M) [application/octet-stream]\n",
            "Saving to: ‘language_perceiver_io_bytes.pickle’\n",
            "\n",
            "language_perceiver_ 100%[===================>] 767.21M   178MB/s    in 4.6s    \n",
            "\n",
            "2021-10-09 19:37:30 (166 MB/s) - ‘language_perceiver_io_bytes.pickle’ saved [804479532/804479532]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38bY4HUgjdT3"
      },
      "source": [
        "\n",
        "#@title Model config\n",
        "D_MODEL = 768\n",
        "D_LATENTS = 1280\n",
        "MAX_SEQ_LEN = 2048\n",
        "\n",
        "encoder_config = dict(\n",
        "    num_self_attends_per_block=26,\n",
        "    num_blocks=1,\n",
        "    z_index_dim=256,\n",
        "    num_z_channels=D_LATENTS,\n",
        "    num_self_attend_heads=8,\n",
        "    num_cross_attend_heads=8,\n",
        "    qk_channels=8 * 32,\n",
        "    v_channels=D_LATENTS,\n",
        "    use_query_residual=True,\n",
        "    cross_attend_widening_factor=1,\n",
        "    self_attend_widening_factor=1)\n",
        "\n",
        "decoder_config = dict(\n",
        "    output_num_channels=D_LATENTS,\n",
        "    position_encoding_type='trainable',\n",
        "    output_index_dims=MAX_SEQ_LEN,\n",
        "    num_z_channels=D_LATENTS,\n",
        "    qk_channels=8 * 32,\n",
        "    v_channels=D_MODEL,\n",
        "    num_heads=8,\n",
        "    final_project=False,\n",
        "    use_query_residual=False,\n",
        "    trainable_position_encoding_kwargs=dict(num_channels=D_MODEL))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwS0656EjhsR"
      },
      "source": [
        "#@title Decoding Perceiver Model\n",
        "def apply_perceiver(\n",
        "    inputs: jnp.ndarray, input_mask: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Runs a forward pass on the Perceiver.\n",
        "\n",
        "  Args:\n",
        "    inputs: input bytes, an int array of shape [B, T]\n",
        "    input_mask: Array of shape indicating which entries are valid and which are\n",
        "      masked. A truthy value indicates that the entry is valid.\n",
        "\n",
        "  Returns:\n",
        "    The output logits, an array of shape [B, T, vocab_size].\n",
        "  \"\"\"\n",
        "  assert inputs.shape[1] == MAX_SEQ_LEN\n",
        "\n",
        "  embedding_layer = hk.Embed(\n",
        "      vocab_size=tokenizer.vocab_size,\n",
        "      embed_dim=D_MODEL)\n",
        "  embedded_inputs = embedding_layer(inputs)\n",
        "\n",
        "  batch_size = embedded_inputs.shape[0]\n",
        "\n",
        "  input_pos_encoding = perceiver.position_encoding.TrainablePositionEncoding(\n",
        "      index_dim=MAX_SEQ_LEN, num_channels=D_MODEL)\n",
        "  embedded_inputs = embedded_inputs + input_pos_encoding(batch_size)\n",
        "  perceiver_mod = perceiver.Perceiver(\n",
        "      encoder=perceiver.PerceiverEncoder(**encoder_config),\n",
        "      decoder=perceiver.BasicDecoder(**decoder_config))\n",
        "  output_embeddings = perceiver_mod(\n",
        "      embedded_inputs, is_training=False, input_mask=input_mask, query_mask=input_mask)\n",
        "\n",
        "  logits = io_processors.EmbeddingDecoder(\n",
        "      embedding_matrix=embedding_layer.embeddings)(output_embeddings)\n",
        "  return logits\n",
        "\n",
        "apply_perceiver = hk.transform(apply_perceiver).apply"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4o2w2Y8jmsh"
      },
      "source": [
        "\n",
        "#@title Pad and reshape inputs\n",
        "inputs = input_tokens[None]\n",
        "input_mask = np.ones_like(inputs)\n",
        "\n",
        "def pad(max_sequence_length: int, inputs, input_mask):\n",
        "  input_len = inputs.shape[1]\n",
        "  assert input_len <= max_sequence_length\n",
        "  pad_len = max_sequence_length - input_len\n",
        "  padded_inputs = np.pad(\n",
        "      inputs,\n",
        "      pad_width=((0, 0), (0, pad_len)),\n",
        "      constant_values=tokenizer.pad_token)\n",
        "  padded_mask = np.pad(\n",
        "      input_mask,\n",
        "      pad_width=((0, 0), (0, pad_len)),\n",
        "      constant_values=0)\n",
        "  return padded_inputs, padded_mask\n",
        "\n",
        "inputs, input_mask = pad(MAX_SEQ_LEN, inputs, input_mask)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XutZVejrtphE",
        "outputId": "793195d8-33f8-43d0-dfaa-1154a1826500"
      },
      "source": [
        "sentences = [\n",
        "'This is the missing word in this sentence',\n",
        "'Situps are a terrible way to end your day',\n",
        "'As time wore on, simple dog commands turned into full paragraphs explaining why the dog couldn’t do something',\n",
        "'Hang on, my kittens are scratching at the bathtub and they are upset by the lack of biscuits',\n",
        "'On a scale from one to ten, what is your favorite flavor of random grammar',\n",
        "'He had a wall full of masks so she could wear a different face every day'\n",
        "'She could not decide of the glass was half empty or half full so she drank it'\n",
        "'The knives were out and she was sharpening hers',\n",
        "'She could not understand why nobody else could see that the sky is full of cotton candy',\n",
        "'The blinking lights of the antenna tower came into focus just as I heard a loud snap',\n",
        "'He wondered if it could be called a beach if there was no sand',\n",
        "'The boy ran up the hill',\n",
        "'What you stay focused on will grow',\n",
        "'Onward and Upward! To Narnia and the North!',\n",
        "'Write while the heat is in you',\n",
        "'The writer who postpones the recording of his thoughts uses an iron which has cooled to burn a hole with. He cannot inflame the minds of his audience',\n",
        "'If you dare nothing, then when the day is over, nothing is all you will have gained',\n",
        "]\n",
        "\n",
        "sentences"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This is the missing word in this sentence',\n",
              " 'Situps are a terrible way to end your day.',\n",
              " 'As time wore on, simple dog commands turned into full paragraphs explaining why the dog couldn’t do something.',\n",
              " 'Hang on, my kittens are scratching at the bathtub and they are upset by the lack of biscuits.',\n",
              " 'On a scale from one to ten, what is your favorite flavor of random grammar?',\n",
              " 'He had a wall full of masks so she could wear a different face every day.She could not decide of the glass was half empty or half full so she drank it.The knives were out and she was sharpening hers.',\n",
              " 'She could not understand why nobody else could see that the sky is full of cotton candy.',\n",
              " 'The blinking lights of the antenna tower came into focus just as I heard a loud snap.',\n",
              " 'He wondered if it could be called a beach if there was no sand.']"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-lt6i08vvkC"
      },
      "source": [
        "def mask_word(sentences, index):\n",
        "  incomplete_sentences = []\n",
        "  missing_word = []\n",
        "  for text in sentences:\n",
        "      entry = {}\n",
        "      incomplete_text = ''\n",
        "      entry['word'] = text.split(\" \")[index]\n",
        "      if index == -1 :\n",
        "        text_preprocessed = text.split(\" \")[:-1]\n",
        "      elif index > 0 and index < len(text):\n",
        "        text_preprocessed = text.split(\" \")[:index] +  text.split(\" \")[index+1:]\n",
        "      else: \n",
        "         text_preprocessed = text.split(\" \")[index:]\n",
        "      incomplete_text = \" \".join(text_preprocessed)\n",
        "      entry['bi'] = text.index(entry['word'])\n",
        "      entry['ei'] = entry['bi'] + len(entry['word']) \n",
        "      missing_word.append(entry)\n",
        "      incomplete_sentences.append(incomplete_text)\n",
        "  return incomplete_sentences, missing_word"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLGTfws4DQOw"
      },
      "source": [
        "def validatePredictions(predictions, expected):\n",
        "  correct = 0\n",
        "  for i in range(len(sentences)):\n",
        "    missing = expected[i]\n",
        "    if predictions[i].lower() == missing['word'].lower():\n",
        "      correct = correct +1\n",
        "\n",
        "    print(\"Actual Sentence\")\n",
        "    print(sentences[i])\n",
        "\n",
        "    print(\"Sentence with Predicted Word\")\n",
        "    print(sentences[i].replace(missing['word'], \"[\"+predictions[i]+\"]\"))\n",
        "    print('\\n')\n",
        "  print(\"Accuracy {}\".format(correct/len(sentences)))\n",
        "    "
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u3zwsrdEb8h"
      },
      "source": [
        "def runExperiment(sentences, index):\n",
        "  incomplete_sentences, missing_word = mask_word(sentences, index)\n",
        "\n",
        "  tokenizer = bytes_tokenizer.BytesTokenizer()\n",
        "\n",
        "  # Encode Sentences\n",
        "  encoded_sentences = []\n",
        "  for text in sentences:\n",
        "    input_tokens = tokenizer.to_int(text)\n",
        "    encoded_sentences.append(input_tokens)\n",
        "\n",
        "  # Apply Missing Mask to sentences\n",
        "  for i in range(len(sentences)):\n",
        "    encoded_sentences[i][missing_word[i]['bi']:missing_word[i]['ei']] = tokenizer.mask_token\n",
        "\n",
        "  input_sentences = [text[None] for text in encoded_sentences]\n",
        "  input_sentence_mask = [np.ones_like(inputs) for inputs in input_sentences] \n",
        "\n",
        "  # Adding Paddings\n",
        "  input_sentence_pad = []\n",
        "  input_sentence_mask_pad = []\n",
        "  for i in range(len(sentences)):\n",
        "    inputs, input_mask = pad(MAX_SEQ_LEN, input_sentences[i], input_sentence_mask[i])\n",
        "    input_sentence_pad.append(inputs)\n",
        "    input_sentence_mask_pad.append(input_mask)\n",
        "\n",
        "  # Run Predictions\n",
        "  rng = jax.random.PRNGKey(1)  # Unused\n",
        "  predictions = []\n",
        "  for i in range(len(sentences)):\n",
        "    out = apply_perceiver(params, rng=rng, inputs=input_sentence_pad[i], input_mask=input_sentence_mask_pad[i])\n",
        "    missing = missing_word[i]\n",
        "    masked_tokens_predictions = out[0, missing['bi']:missing['ei']].argmax(axis=-1)\n",
        "    predictions.append(tokenizer.to_string(masked_tokens_predictions))  \n",
        "\n",
        "  validatePredictions(predictions,missing_word)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d8XF_wlFQmE",
        "outputId": "205bac0e-4bf2-4556-8d8c-004e64ff9ef8"
      },
      "source": [
        "# What is the accuracy when front of sentence is missing?\n",
        "runExperiment(sentences, 0)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Sentence\n",
            "This is the missing word in this sentence\n",
            "Sentence with Predicted Word\n",
            "[What] is the missing word in this sentence\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "Situps are a terrible way to end your day.\n",
            "Sentence with Predicted Word\n",
            "[ tiees] are a terrible way to end your day.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "As time wore on, simple dog commands turned into full paragraphs explaining why the dog couldn’t do something.\n",
            "Sentence with Predicted Word\n",
            "[as] time wore on, simple dog commands turned into full paragraphs explaining why the dog couldn’t do something.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "Hang on, my kittens are scratching at the bathtub and they are upset by the lack of biscuits.\n",
            "Sentence with Predicted Word\n",
            "[  no] on, my kittens are scratching at the bathtub and they are upset by the lack of biscuits.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "On a scale from one to ten, what is your favorite flavor of random grammar?\n",
            "Sentence with Predicted Word\n",
            "[on] a scale from one to ten, what is your favorite flavor of random grammar?\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "He had a wall full of masks so she could wear a different face every day.She could not decide of the glass was half empty or half full so she drank it.The knives were out and she was sharpening hers.\n",
            "Sentence with Predicted Word\n",
            "[ t] had a wall full of masks so she could wear a different face every day.She could not decide of the glass was half empty or half full so she drank it.The knives were out and she was sharpening hers.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "She could not understand why nobody else could see that the sky is full of cotton candy.\n",
            "Sentence with Predicted Word\n",
            "[  I] could not understand why nobody else could see that the sky is full of cotton candy.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "The blinking lights of the antenna tower came into focus just as I heard a loud snap.\n",
            "Sentence with Predicted Word\n",
            "[the] blinking lights of the antenna tower came into focus just as I heard a loud snap.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "He wondered if it could be called a beach if there was no sand.\n",
            "Sentence with Predicted Word\n",
            "[ I] wondered if it could be called a beach if there was no sand.\n",
            "\n",
            "\n",
            "Accuracy 0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6g4i0y2FueF",
        "outputId": "120934ee-8225-448c-93ee-1306166cefbd"
      },
      "source": [
        "runExperiment(sentences,-1)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Sentence\n",
            "This is the missing word in this sentence\n",
            "Sentence with Predicted Word\n",
            "This is the missing word in this [ perase.]\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "Situps are a terrible way to end your day.\n",
            "Sentence with Predicted Word\n",
            "Situps are a terrible way to end your [ Rd.]\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "As time wore on, simple dog commands turned into full paragraphs explaining why the dog couldn’t do something.\n",
            "Sentence with Predicted Word\n",
            "As time wore on, simple dog commands turned into full paragraphs explaining why the dog couldn’t do [ see   the]\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "Hang on, my kittens are scratching at the bathtub and they are upset by the lack of biscuits.\n",
            "Sentence with Predicted Word\n",
            "Hang on, my kittens are scratching at the bathtub and they are upset by the lack of [ wateee..]\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "On a scale from one to ten, what is your favorite flavor of random grammar?\n",
            "Sentence with Predicted Word\n",
            "On a scale from one to ten, what is your favorite flavor of random [ coenes?]\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "He had a wall full of masks so she could wear a different face every day.She could not decide of the glass was half empty or half full so she drank it.The knives were out and she was sharpening hers.\n",
            "Sentence with Predicted Word\n",
            "He had a wall full of masks so she could wear a different face every day.She could not decide of the glass was half empty or half full so she drank it.The knives were out and she was sharpening [     ]\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "She could not understand why nobody else could see that the sky is full of cotton candy.\n",
            "Sentence with Predicted Word\n",
            "She could not understand why nobody else could see that the sky is full of cotton [ bao  ]\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "The blinking lights of the antenna tower came into focus just as I heard a loud snap.\n",
            "Sentence with Predicted Word\n",
            "The blinking lights of the antenna tower came into focus just as I heard a loud [ cry.]\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "He wondered if it could be called a beach if there was no sand.\n",
            "Sentence with Predicted Word\n",
            "He wondered if it could be called a beach if there was no [  ne.]\n",
            "\n",
            "\n",
            "Accuracy 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pG0RYsxF7kC",
        "outputId": "36f34d0c-4747-45f2-fe0b-c7d318ca5283"
      },
      "source": [
        "runExperiment(sentences,5)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Sentence\n",
            "This is the missing word in this sentence\n",
            "Sentence with Predicted Word\n",
            "This is the miss[ a]g word [ a] this sentence\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "Situps are a terrible way to end your day.\n",
            "Sentence with Predicted Word\n",
            "Situps are a terrible way [  ] end your day.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "As time wore on, simple dog commands turned into full paragraphs explaining why the dog couldn’t do something.\n",
            "Sentence with Predicted Word\n",
            "As time wore on, simple [ of] commands turned into full paragraphs explaining why the [ of] couldn’t do something.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "Hang on, my kittens are scratching at the bathtub and they are upset by the lack of biscuits.\n",
            "Sentence with Predicted Word\n",
            "Hang on, my kittens are [ soi ng up] at the bathtub and they are upset by the lack of biscuits.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "On a scale from one to ten, what is your favorite flavor of random grammar?\n",
            "Sentence with Predicted Word\n",
            "On a scale from one [ o] ten, what is your favorite flavor of random grammar?\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "He had a wall full of masks so she could wear a different face every day.She could not decide of the glass was half empty or half full so she drank it.The knives were out and she was sharpening hers.\n",
            "Sentence with Predicted Word\n",
            "He had a wall full [  ] masks so she could wear a different face every day.She could not decide [  ] the glass was half empty or half full so she drank it.The knives were out and she was sharpening hers.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "She could not understand why nobody else could see that the sky is full of cotton candy.\n",
            "Sentence with Predicted Word\n",
            "She could not understand why [ n  ne] else could see that the sky is full of cotton candy.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "The blinking lights of the antenna tower came into focus just as I heard a loud snap.\n",
            "Sentence with Predicted Word\n",
            "The blinking lights of the [  f the] tower came into focus just as I heard a loud snap.\n",
            "\n",
            "\n",
            "Actual Sentence\n",
            "He wondered if it could be called a beach if there was no sand.\n",
            "Sentence with Predicted Word\n",
            "He wondered if it could [  ] called a [  ]ach if there was no sand.\n",
            "\n",
            "\n",
            "Accuracy 0.0\n"
          ]
        }
      ]
    }
  ]
}